#!/usr/bin/env python
import logging

from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter, FileType
from json import load
from logging import WARNING, DEBUG
from multiprocessing import Process
from random import choice, random
from signal import signal, SIGINT, SIG_IGN, SIGTERM
from time import sleep
from traceback import format_exc
from uuid import uuid4

from spotify.docker_stress.mail import send_mail
from spotify.docker_stress.await import await
from spotify.docker_stress.docker_client import CliDockerClient
from spotify.docker_stress.docker_client import DEFAULT_DOCKER_CLI
from spotify.docker_stress.docker_client import DEFAULT_DOCKER_ENDPOINT
from spotify.docker_stress.docker_util import running, connectable, endpoint_address
from spotify.docker_stress.docker_util import successfully_destroyed, destroy_containers
from spotify.docker_stress.rate_limit import rate_limited


log = logging.getLogger('docker-stress')


@rate_limited('email', 20, 0.005)
def send_alert(email=None, message=None):
    send_mail(to=email, message=message)


def work(client=None, job=None, hostname=None, nametag=None, ttl=None):
    assert client and job and hostname and nametag
    print 'starting job: %s' % job

    name = "stress_" + nametag + "_" + uuid4().hex[:10]
    try:
        container_id = client.start_new(name=name, **job)
        await('running', lambda: running(client, container_id))
        # TODO (dano): Make this more evil and kill it etc in mid-setup
        await('connectable', lambda: connectable(client, container_id, hostname, job.get('ports', [])))
        if ttl:
            sleep(ttl)
        client.kill(container_id)
        await('not running after kill', lambda: not running(client, container_id))
        await('destroy', lambda: successfully_destroyed(client, container_id))
        await('inspect after destroy', lambda: not client.inspect_container(container_id))
    except Exception, e1:
        try:
            client.kill(name)
        except Exception, e2:
            log.debug('kill failed: %s', e2)
        try:
            client.destroy(name)
        except Exception, e2:
            log.debug('destroy failed: %s', e2)
        raise e1


def worker(client=None, jobs=None, email=None, **kwargs):
    assert client and jobs
    # Let parent deal with Ctrl-C
    signal(SIGINT, SIG_IGN)
    while True:
        try:
            work(client=client, job=choice(jobs), **kwargs)
        except Exception, e:
            log.error('failure: %s', e)
            send_alert(email=email, message='failure: %s\n\n%s' % (e, format_exc()))
            sleep(1)


def spawn(f, *args, **kwargs):
    t = Process(target=f, args=args, kwargs=kwargs)
    t.start()
    return t


def after(delay, f):
    sleep(delay)
    return f()


def main():
    parser = ArgumentParser(description='docker stress test', formatter_class=ArgumentDefaultsHelpFormatter)
    parser.add_argument('-f', '--jobs', default='jobs.json', type=FileType('r'), help='jobs file')
    parser.add_argument('-d', '--cli', default=DEFAULT_DOCKER_CLI, help='docker cli')
    parser.add_argument('-H', '--endpoint', default=DEFAULT_DOCKER_ENDPOINT, help='docker endpoint')
    parser.add_argument('-c', '--concurrency', type=int, default=1, help='number of containers to run concurrently')
    parser.add_argument('-t', '--ttl', type=int, default=0, help='Time in seconds to let containers run')
    parser.add_argument('-e', '--email', nargs='*', type=str, help='Email address to spam with failure alerts')
    parser.add_argument('-v', '--verbosity', action='count', default=0)

    args = parser.parse_args()

    logging.basicConfig(format='%(asctime)s %(levelname)-7s %(filename)s:%(lineno)d %(message)s',
                        level=max(DEBUG, WARNING - args.verbosity * 10))

    client = CliDockerClient(docker=args.cli, endpoint=args.endpoint)

    hostname = endpoint_address(args.endpoint)

    jobs = load(args.jobs)
    log.debug('jobs: %s', jobs)

    workers = []
    nametag = uuid4().hex[:10]

    def kill_workers():
        for p in workers:
            try:
                p.terminate()
            except Exception, e:
                log.debug(e)
                pass
            try:
                p.join()
            except Exception, e:
                log.debug(e)
                pass

    def start_worker():
        return spawn(worker,
                     client=client,
                     jobs=jobs,
                     hostname=hostname,
                     nametag=nametag,
                     email=args.email,
                     ttl=args.ttl)

    # Ensure that we get to clean up even if we get a SIGTERM
    signal(SIGTERM, lambda signum, stack_frame: exit(1))

    try:
        workers.extend(after(random(), start_worker) for i in xrange(args.concurrency))
        while True:
            sleep(1)
    except KeyboardInterrupt:
        pass
    finally:
        print "Terminating workers and cleaning up...(in background)"
        kill_workers()
        destroy_containers(client, nametag)


if __name__ == '__main__':
    main()
